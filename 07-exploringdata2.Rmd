# Exploring data #2

[Download](https://github.com/geanders/RProgrammingForResearch/raw/master/slides/CourseNotes_Week7.pdf) a pdf of the lecture slides covering this topic.

```{r echo = FALSE, message = FALSE}
library(tidyverse)
library(knitr)
library(faraway)
data(worldcup)
library(ggthemes)
```

## Parentheses

If you put parentheses around an entire code statement, it will both run the code and print out the answer.

```{r}
study_months <- c("Jan", "Feb", "Mar")
study_months

(study_months <- c("Jan", "Feb", "Mar"))
```

## Loops

Loops allow you to "walk through" and repeat the same code for different values of an index. For each run of the loop, R is told that, for **some index** in **some vector**, do **some code**. For example, the following loop specifies: For `i` in `1:3`, `print(i)`.

```{r}
for(i in c(1, 2, 3)){
        print(i)
}
```

Note that this code is equivalent to: 

```{r}
i <- 1
print(i)
i <- 2
print(i)
i <- 3
print(i)
```

Often, the index will be set to a number for each cycle of the loop, and then the index will be used within the code to index vectors or dataframes: 

```{r}
study_months <- c("Jan", "Feb", "Mar")
for(i in c(1, 3)){
        print(study_months[i])
}
```

Often, you want to set the index to sequential numbers (e.g., 1, 2, 3, 4). In this case, you can save time by using the `:` notation to create a vector of a sequence of numbers:

```{r}
for(i in 1:3){
        print(i)
}
```

With this notation, sometimes it may be helpful to use the `length` function to set the largest index value for the loop as the length of a vector (or `nrow` for indexing a dataframe). For example:

```{r}
study_months <- c("Jan", "Feb", "Mar")
for(i in 1:length(study_months)){
        print(study_months[i])
}
```

Sometimes, you want to set the index for each cycle of the loop to something that is not a number. You can set the index to any class of vector. 

Remember that a loop works by saying for **some index** in **some vector**, do **some code**. For example, you may want to run: for `study_month` in `study_months`, `print(study_month)`:

```{r}
study_months <- c("Jan", "Feb", "Mar")
for(study_month in study_months){
        print(study_month)
}
```

Note that this is equivalent to: 

```{r}
study_month <- "Jan"
print(study_month)
study_month <- "Feb"
print(study_month)
study_month <- "Mar"
print(study_month)
```

What would this loop do?

```{r, eval = FALSE}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
for(i in 1:length(vars)){
        var_mean <- mean(worldcup[ , vars[i]])
        print(var_mean)
}
```

```{r}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
for(i in 1:length(vars)){
        var_mean <- mean(worldcup[ , vars[i]])
        print(var_mean)
}
```

What would this loop do?

```{r, eval = FALSE}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
for(i in 1:length(vars)){
        var_mean <- mean(worldcup[ , vars[i]])
        var_mean <- round(var_mean, 1)
        out <- paste0("mean of ", vars[i], ": ", var_mean)
        print(out)
}
```

To figure out, you can set `i <- 1` and then walk through the loop:

```{r}
i <- 1
(var_mean <- mean(worldcup[ , vars[i]]))
(var_mean <- round(var_mean, 1))
(out <- paste0("mean of ", vars[i], ": ", var_mean))
```

```{r}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
for(i in 1:length(vars)){
        var_mean <- mean(worldcup[ , vars[i]])
        var_mean <- round(var_mean, 1)
        out <- paste0("mean of ", vars[i], ": ", var_mean)
        print(out)
}
```

Often, it's convenient to create a dataset to fill up as you loop through:

```{r, eval = FALSE}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
my_df <- data.frame(variable = vars, mean = NA)
for(i in 1:nrow(my_df)){
        var_mean <- mean(worldcup[ , vars[i]])
        my_df[i , "mean"] <- round(var_mean, 1)
}
```


```{r}
vars <- c("Time", "Shots", "Passes", "Tackles", "Saves")
(my_df <- data.frame(variable = vars, mean = NA))
```

```{r}
i <- 1
(var_mean <- mean(worldcup[ , vars[i]]))
my_df[i , "mean"] <- round(var_mean, 1)
my_df
```


```{r}
for(i in 1:nrow(my_df)){
        var_mean <- mean(worldcup[ , vars[i]])
        my_df[i , "mean"] <- round(var_mean, 1)
}
my_df
```

Note: This is a pretty simplistic example. There are some easier ways to have done this:

```{r}
worldcup %>% 
  summarize(Time = mean(Time), Passes = mean(Passes),
            Shots = mean(Shots), Tackles = mean(Tackles),
            Saves = mean(Saves)) %>%
  gather(key = var, value = mean) %>%
  mutate(mean = round(mean, 1))
```

Another way to have done this is with `apply`:

```{r}
means <- apply(worldcup[ , vars], 2, mean)
(means <- round(means, 1))
```

However, you can use this same looping process for much more complex tasks that you can't do as easily with `apply` or `dplyr` tools.

Loops can be very useful for more complex repeated tasks. For example:

```{r, echo = FALSE, fig.width = 6, fig.height = 4}
positions <- unique(worldcup$Position)
pos_est <- data.frame(position = positions,
                      est = NA, se = NA)

for(i in 1:nrow(pos_est)){
        pos_df <- worldcup %>% 
          filter(Position == positions[i]) 
        pos_mod <- glm(Passes ~ Time,
                       data = pos_df,
                       family = poisson(link = "log"))
        pos_coefs <- summary(pos_mod)$coefficients[2, 1:2]
        pos_est[i, c("est", "se")] <- pos_coefs
}

pos_est <- pos_est %>%
  mutate(lower_ci = est - 1.96 * se,
         upper_ci = est + 1.96 * se)

rr_per90 <- function(est){
        out <- exp(est * 90)
        return(out)
}

pos_est[ , c("rr_est", "rr_low", "rr_high")] <- 
        apply(pos_est[ , c("est", "lower_ci", "upper_ci")], 2, rr_per90)

pos_est <- arrange(pos_est, rr_est) %>%
        mutate(position = factor(position, levels = position))

ggplot(pos_est, aes(x = rr_low, y = position)) + 
        geom_segment(aes(xend = rr_high, yend = position)) + 
        geom_point(aes(x = rr_est, y = position)) + 
        theme_few() + 
        ylab("") + 
        scale_x_continuous("Relative rate of passes\nper 90 minute increase in minutes played",
                           limits = c(1.0, max(pos_est$rr_high))) + 
        geom_vline(aes(xintercept = 1), color = "lightgray")
```

Creating this graph requires that you: 

- Create a subset limited to each of the four positions
- Fit a Poisson regression of Passes on Time within each subset
- Pull the regression coefficient and standard error from each model
- Use those values to calculate 95% confidence intervals
- Convert everything from log relative rate to relative rate
- Plot everything

Create a vector with the names of all positions. Create an empty dataframe to store regression results:

```{r}
(positions <- unique(worldcup$Position))
(pos_est <- data.frame(position = positions,
                       est = NA, se = NA))
```

Loop through and fit a Poisson regression model for each subset of data. Save regression coefficients in the empty dataframe:

```{r}
for(i in 1:nrow(pos_est)){
        pos_df <- worldcup %>%
          filter(Position == positions[i]) 
        pos_mod <- glm(Passes ~ Time,
                       data = pos_df,
                       family = poisson(link = "log"))
        pos_coefs <- summary(pos_mod)$coefficients[2, 1:2]
        pos_est[i, c("est", "se")] <- pos_coefs
}
pos_est[1:2, ]
```

Calculate 95% confidence intervals for log relative risk values:

```{r}
pos_est <- pos_est %>%
  mutate(lower_ci = est - 1.96 * se,
         upper_ci = est + 1.96 * se)

pos_est %>%
  select(position, est, lower_ci, upper_ci) 
```

Calculate relative risk per 90 minute increase in minutes played: 

```{r}
pos_est <- pos_est %>%
  mutate(rr_est = exp(90 * est),
         rr_low = exp(90 * lower_ci),
         rr_high = exp(90 * upper_ci))
pos_est %>%
  select(position, rr_est, rr_low, rr_high) 
```

Re-level the `position` factor so the plot will be ordered from highest to lowest estimates:

```{r}
pos_est <- arrange(pos_est, rr_est) %>%
        mutate(position = factor(position,
                                 levels = position))
pos_est %>% select(position, est)
```

Create the plot:

```{r, fig.width = 6, fig.height = 4}
ggplot(pos_est, aes(x = rr_low, y = position)) + 
        geom_segment(aes(xend = rr_high, yend = position)) + 
        geom_point(aes(x = rr_est, y = position)) + 
        theme_few() + 
        ylab("") + 
        scale_x_continuous(paste("Relative rate of passes\nper",
                                 "90 minute increase in minutes played"),
                           limits = c(1.0, max(pos_est$rr_high))) + 
        geom_vline(aes(xintercept = 1), color = "lightgray")
```

## Other control structures

### if / else loops 

There are other control structures you can use in your R code. Two that you will commonly use within R functions are `if` and `ifelse` statements. \bigskip

An `if` statement tells R that, **if** a certain condition is true, **do** run some code. For example, if you wanted to print out only odd numbers between 1 and 5, one way to do that is with an `if` statement: (Note: the `%%` operator in R returns the remainder of the first value (i) divided by the second value (2).) 

```{r}
for(i in 1:5){
  if(i %% 2 == 1){
    print(i)
  }
}
```

The `if` statement runs some code if a condition is true, but does nothing if it is false. If you'd like different code to run depending on whether the condition is true or false, you can us an if / else or an if / else if / else statement. 

```{r}
for(i in 1:5){
  if(i %% 2 == 1){
    print(i)
  } else {
    print(paste(i, "is even"))
  }
}
```

What would this code do? \bigskip 

```{r eval = FALSE}
for(i in 1:100){
  if(i %% 3 == 0 & i %% 5 == 0){
    print("FizzBuzz")
  } else if(i %% 3 == 0){
    print("Fizz")
  } else if(i %% 5 == 0){
    print("Buzz")
  } else {
    print(i)
  }
}
```

If / else statements are extremely useful in functions. \bigskip

In R, the `if` statement evaluates everything in the parentheses and, if that evaluates to `TRUE`, runs everything in the braces. This means that you can trigger code in an `if` statement with a single-value logical vector: 

```{r}
weekend <- TRUE
if(weekend){
  print("It's the weekend!")
}
```

This functionality can be useful with parameters you choose to include when writing your own functions (e.g., `print = TRUE`).

### Some other control structures

The control structures you are most likely to use in data analysis with R are "for" loops and "if / else" statements. However, there are a few other control structures you may occasionally find useful: 

- `next`
- `break`
- `while`

You can use the `next` structure to skip to the next round of a loop when a certain condition is met. For example, we could have used this code to print out odd numbers between 1 and 5:

```{r}
for(i in 1:5){
  if(i %% 2 == 0){
    next
  }
  print(i)
}
```

You can use `break` to break out of a loop if a certain condition is met. For example, the final code will break out of the loop once `i` is over 3, so it will only print the numbers 1 through 3:

```{r}
for(i in 1:5){
  if(i > 3){
    break
  }
  print(i)
}
```

```{r}
my_sum <- 1
while(my_sum < 10){
  my_sum <- my_sum * 2
  print(my_sum)
}
```

## Functions

As you move to larger projects, you will find yourself using the same code a lot. \bigskip

Examples include: 

- Reading in data from a specific type of equipment (air pollution monitor, accelerometer)
- Running a specific type of analysis
- Creating a specific type of plot or map

\bigskip 

If you find yourself cutting and pasting a lot, convert the code to a function.

Advantages of writing functions include: 

- Coding is more efficient
- Easier to change your code (if you've cut and paste code and you want to change something, you have to change it everywhere - this is an easy way to accidentally create bugs in your code)
- Easier to share code with others

You can name a function anything you want (although try to avoid names of preexisting-existing functions). You then define any inputs (arguments; separate multiple arguments with commas) and put the code to run in braces:

```{r, eval = FALSE}
## Note: this code will not run
[function name] <- function([any arguments]){
        [code to run]
}
```

Here is an example of a very basic function. This function takes a number as input and adds 1 to that number. 

```{r}
add_one <- function(number){
        out <- number + 1
        return(out)
}

add_one(number = 3)
add_one(number = -1)
```

- Functions can input any type of R object (for example, vectors, data frames, even other functions and ggplot objects)
- Similarly, functions can output any type of R object
- When defining a function, you can set default values for some of the parameters
- You can explicitly specify the value to return from the function
- There are ways to check for errors in the arguments a user inputs to the function

For example, the following function inputs a data frame (`datafr`) and a one-element vector (`child_id`) and returns only rows in the data frame where it's `id` column matches `child_id`. It includes a default value for `datafr`, but not for `child_id`. 

```{r}
subset_nepali <- function(datafr = nepali, child_id){
  datafr <- datafr %>%
    filter(id == child_id)
  return(datafr)
}
```

If an argument is not given for a parameter with a default, the function will run using the default value for that parameter. For example:

```{r}
subset_nepali(child_id = "120011")
```


If an argument is not given for a parameter without a default, the function call will result in an error. For example:

```{r error = TRUE}
subset_nepali(datafr = nepali)
```

By default, the function will return the last defined object, although the choice of using `return` can affect printing behavior when you run the function. For example, I could have written the `subset_nepali` function like this: 

```{r}
subset_nepali <- function(datafr = nepali, child_id){
  datafr <- datafr %>%
    filter(id == child_id)
}
```

In this case, the output will not automatically print out when you call the function without assigning it to an R object:

```{r}
subset_nepali(child_id = "120011")
```

However, the output can be assigned to an R object in the same way as when the function was defined without `return`:

```{r}
first_childs_data <- subset_nepali(child_id = "120011")
first_childs_data
```

The `return` function can also be used to return an object other than the last defined object (although doesn't tend to be something you need to do very often). For example, if you did not use `return` in the following code, it will output "Test output":

```{r}
subset_nepali <- function(datafr = nepali, child_id){
  datafr <- datafr %>%
    filter(id == child_id)
  a <- "Test output"
}
(subset_nepali(child_id = "120011"))
```

Conversely, you can use `return` to output `datafr`, even though it's not the last object defined:

```{r}
subset_nepali <- function(datafr = nepali, child_id){
  datafr <- datafr %>%
    filter(id == child_id)
  a <- "Test output"
  return(datafr)
}
subset_nepali(child_id = "120011")
```

You can use `stop` to stop execution of the function and give the user an error message. For example, the `subset_nepali` function will fail if the user inputs a data frame that does not have a column named "id":

```{r eval = FALSE}
subset_nepali(datafr = data.frame(wt = rnorm(10)),
              child_id = "12011")
```
```
 Error: comparison (1) is possible only for 
 atomic and list types 
```

You can rewrite the function to stop if the input `datafr` does not have a column named "id":

```{r eval = FALSE}
subset_nepali <- function(datafr = nepali, child_id){
  if(!("id" %in% colnames(datafr))){
    stop("`datafr` must include a column named `id`")
  }
  datafr <- datafr %>%
    filter(id == child_id)
  return(datafr)
}
subset_nepali(datafr = data.frame(wt = rnorm(10)),
              child_id = "12011")
```

```
Error in subset_nepali(datafr = data.frame(wt = rnorm(10)),
child_id = "12011") : 
  `datafr` must include a column named `id`
```

The `stop` function is particularly important if the function would keep running with the wrong input, but would result in the wrong output. \bigskip

You can also output warnings and messages using the functions `warning` and `message`.


## Regular expressions

For these examples, we'll use some data on passengers of the Titanic. You can load this data using:

```{r}
# install.packages("titanic")
library(titanic)
data("titanic_train")
```

We will be using the `stringr` package:

```{r}
library(stringr)
```

This data includes a column called "Name" with passenger names. This column is somewhat messy and includes several elements that we might want to separate (last name, first name, title). Here are the first few values of "Name": 

```{r}
titanic_train %>% select(Name) %>% slice(1:3)
```

We've already done some things to manipulate strings. For example, if we wanted to separate "Name" into last name and first name (including title), we could actually do that with the `separate` function: 

```{r}
titanic_train %>% 
  select(Name) %>% 
  slice(1:3) %>% 
  separate(Name, c("last_name", "first_name"), sep = ", ")
```


Notice that `separate` is looking for a regular pattern (", ") and then doing something based on the location of that pattern in each string (splitting the string). \bigskip

There are a variety of functions in R that can perform manipulations based on finding regular patterns in character strings. 


The `str_detect` function will look through each element of a character vector for a designated pattern. If the pattern is there, it will return `TRUE`, and otherwise `FALSE`. The convention is: 

```
## Generic code
str_detect(string = [vector you want to check], 
           pattern = [pattern you want to check for])
```

For example, to create a logical vector specifying which of the Titanic passenger names include "Mrs.", you can call:

```{r}
mrs <- str_detect(titanic_train$Name, "Mrs.")
head(mrs)
```


The result is a logical vector, so `str_detect` can be used in `filter` to subset data to only rows where the passenger's name includes "Mrs.":

```{r}
titanic_train %>%
  filter(str_detect(Name, "Mrs.")) %>%
  select(Name) %>%
  slice(1:3)
```


There is an older, base R function called `grepl` that does something very similar (although note that the order of the arguments is reversed).

```{r}
titanic_train %>%
  filter(grepl("Mrs.", Name)) %>%
  select(Name) %>%
  slice(1:3)
```

The `str_extract` function can be used to extract a string (if it exists) from each value in a character vector. It follows similar conventions to `str_detect`:

```
## Generic code
str_extract(string = [vector you want to check], 
           pattern = [pattern you want to check for])
```


For example, you might want to extract "Mrs." if it exists in a passenger's name:

```{r}
titanic_train %>%
  mutate(mrs = str_extract(Name, "Mrs.")) %>%
  select(Name, mrs) %>%
  slice(1:3)
```

Notice that now we're creating a new column (`mrs`) that either has "Mrs." (if there's a match) or is missing (`NA`) if there's not a match. 


For this first example, we were looking for an exact string ("Mrs"). However, you can use patterns that match a particular pattern, but not an exact string. For example, we could expand the regular expression to find "Mr." or "Mrs.": 

```{r}
titanic_train %>%
  mutate(title = str_extract(Name, "Mr\\.|Mrs\\.")) %>%
  select(Name, title) %>%
  slice(1:3)
```

Note that this pattern uses a special operator (`|`) to find one pattern **or** another. Double backslashes (`\\`) **escape** the special character ".". 


As a note, in regular expressions, all of the following characters are special characters that need to be escaped with backslashes if you want to use them literally: 

```
. * + ^ ? $ \ | ( ) [ ] { }
```


Notice that "Mr." and "Mrs." both start with "Mr", end with ".", and may or may not have an "s" in between. 

```{r}
titanic_train %>%
  mutate(title = str_extract(Name, "Mr(s)*\\.")) %>%
  select(Name, title) %>%
  slice(1:3)
```

This pattern uses `(s)*` to match zero or more "s"s at this spot in the pattern. 


In the previous code, we found "Mr." and "Mrs.", but missed "Miss.". We could tweak the pattern again to try to capture that, as well. For all three, we have the pattern that it starts with "M", has some lowercase letters, and then ends with ".".  

```{r}
titanic_train %>%
  mutate(title = str_extract(Name, "M[a-z]+\\.")) %>%
  select(Name, title) %>%
  slice(1:3)
```


The last pattern used `[a-z]+` to match one or more lowercase letters. The `[a-z]`is a **character class**. \bigskip 

You can also match digits (`[0-9]`), uppercase letters (`[A-Z]`), just some letters (`[aeiou]`), etc. \bigskip

You can negate a character class by starting it with `^`. For example, `[^0-9]` will match anything that **isn't** a digit. 


Sometimes, you want to match a pattern, but then only subset a part of it. For example, each passenger seems to have a title ("Mr.", "Mrs.", etc.) that comes after ", " and before ". ". We can use this pattern to find the title, but then we get some extra stuff with the match: 

```{r}
titanic_train %>%
  mutate(title = str_extract(Name, ",\\s[A-Za-z]*\\.\\s")) %>%
  select(title) %>%
  slice(1:3)
```

As a note, in this pattern, `\\s` is used to match a space. 


We are getting things like ", Mr. ", when we really want "Mr". We can use the `str_match` function to do this. We group what we want to extract from the pattern in parentheses, and then the function returns a matrix. The first column is the full pattern match, and each following column gives just what matches within the groups. 

```{r}
head(str_match(titanic_train$Name,
          pattern = ",\\s([A-Za-z]*)\\.\\s"))
```


To get just the title, then, we can run:

```{r}
titanic_train %>%
  mutate(title = 
           str_match(Name, ",\\s([A-Za-z]*)\\.\\s")[ , 2]) %>%
  select(Name, title) %>%
  slice(1:3)
```

The `[ , 2]` pulls out just the second column from the matrix returned by `str_match`. 


Here are some of the most common titles: 

```{r}
titanic_train %>%
  mutate(title = 
           str_match(Name, ",\\s([A-Za-z]*)\\.\\s")[ , 2]) %>%
  group_by(title) %>% summarize(n = n()) %>%
  arrange(desc(n)) %>% slice(1:5)
```


Here are a few other examples of regular expressions in action with this dataset. \bigskip

Get just names that start with ("^") the letter "A":

```{r}
titanic_train %>%
  filter(str_detect(Name, "^A")) %>%
  select(Name) %>%
  slice(1:3)
```


Get names with "II" or "III" (`{2,}` says to match at least two times):

```{r}
titanic_train %>%
  filter(str_detect(Name, "I{2,}")) %>%
  select(Name) %>%
  slice(1:3)
```


Get names with "Andersen" or "Anderson" (alternatives in square brackets):

```{r}
titanic_train %>%
  filter(str_detect(Name, "Anders[eo]n")) %>%
  select(Name)
```



Get names that start with ("^" outside of brackets) the letters "A" and "B":

```{r}
titanic_train %>%
  filter(str_detect(Name, "^[AB]")) %>%
  select(Name) %>%
  slice(1:3)
```


Get names that end with ("$") the letter "b" (either lowercase or uppercase):

```{r}
titanic_train %>%
  filter(str_detect(Name, "[bB]$")) %>%
  select(Name) 
```


Some useful regular expression operators include: 

```{r echo = FALSE}
reg_exp <- data_frame("Operator" = c(".",
                                     "*",
                                     "*?",
                                     "+",
                                     "+?",
                                     "^",
                                     "$", 
                                     "[...]"),
                      "Meaning" = c("Any character", 
                                    "Match 0 or more times (greedy)",
                                    "Match 0 or more times (non-greedy)",
                                    "Match 1 or more times (greedy)",
                                    "Match 1 or more times (non-greedy)",
                                    "Starts with (in brackets, negates)",
                                    "Ends with",
                                    "Character classes"))
knitr::kable(reg_exp)
```


For more on these patterns, see: 

- Help file for the `stringi-search-regex` function in the `stringi` package (which should install when you install `stringr`)
- [Introduction to stringr](https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html) by Hadley Wickham
- [Handling and Processing Strings in R](http://gastonsanchez.com/Handling_and_Processing_Strings_in_R.pdf) by Gaston Sanchez (seven chapter ebook)
- http://gskinner.com/RegExr and http://www.txt2re.com: Interactive tools for helping you build regular expression pattern strings

## In-course exercise

### Exploring Fatality Analysis Reporting System (FARS) data

- Visit http://metrocosm.com/10-years-of-traffic-accidents-mapped.html and explore the interactive visualization created by Max Galka using this public dataset on US fatal motor vehicle accidents.
- Go to [FARS web page](http://www.nhtsa.gov/Data/Fatality-Analysis-Reporting-System-(FARS)) to find and download the data for this week's exercise. We want to get the raw data on fatal accidents. Navigate this page to figure out how you can get this raw data for the whole county for 2015. Download the 2015 data to your computer. What is the structure of how this data is saved (e.g., directory structure, file structure)?
- On the [FARS web page](http://www.nhtsa.gov/Data/Fatality-Analysis-Reporting-System-(FARS)), find the documentation describing this raw data. Look through both this documentation and the raw files you downloaded to figure out what information is included in the data. 
- Read the `accident.csv` file for 2015 into R (this is one of the files you'll get if you download the raw data for 2015). Use the documentation to figure out what each column represents. 
- Discuss what steps you would need to take to create the following plot. To start, don't write any code, just develop a plan. Talk about what the dataset should look like right before you create the plot and what functions you could use to get the data from its current format to that format. (Hint: Functions from the `lubridate` package will be very helpful, including `yday` and `wday`).
- Discuss which of the variables in this dataset could be used to merge the dataset with other appropriate data, either other datasets in the FARS raw data, or outside datasets. 
- Try to write the code to create the plot below. This will include some code for cleaning the data and some code for plotting. There is an example answer below, but I'd like you to try to figure it out yourselves first.

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.width = 6, fig.height = 3, fig.align = "center"}
library(tidyverse)
library(lubridate)
library(ggthemes)

accident <- read_csv("data/accident.csv") %>%
  select(DAY:MINUTE) %>%
  select(-DAY_WEEK) %>%
  unite(date, DAY:MINUTE, sep = "-", remove = FALSE) %>%
  mutate(date = dmy_hm(date), 
         yday = yday(date),
         weekday = wday(date, label = TRUE, abbr = FALSE),
         weekend = weekday %in% c("Saturday", "Sunday")) 

accident %>% 
  filter(!is.na(yday)) %>%
  group_by(yday) %>%
  summarize(accidents = n(),
            weekend = first(weekend)) %>%
  ggplot(aes(x = yday, y = accidents, color = weekend)) + 
  geom_point(alpha = 0.5) + 
  xlab("Day of the year in 2015") + 
  ylab("# of fatal accidents") + 
  theme_few() + 
  geom_smooth(se = FALSE)
```

#### Example R code

Here is example code for the section above: 

```{r warning = FALSE, message = FALSE, fig.width = 6, fig.height = 3, fig.align = "center"}
library(tidyverse)
library(lubridate)
library(ggthemes)

accident <- read_csv("data/accident.csv") %>%
  select(DAY:MINUTE) %>%
  select(-DAY_WEEK) %>%
  unite(date, DAY:MINUTE, sep = "-", remove = FALSE) %>%
  mutate(date = dmy_hm(date), 
         yday = yday(date),
         weekday = wday(date, label = TRUE, abbr = FALSE),
         weekend = weekday %in% c("Saturday", "Sunday")) 

accident %>% 
  filter(!is.na(yday)) %>%
  group_by(yday) %>%
  summarize(accidents = n(),
            weekend = first(weekend)) %>%
  ggplot(aes(x = yday, y = accidents, color = weekend)) + 
  geom_point(alpha = 0.5) + 
  xlab("Day of the year in 2015") + 
  ylab("# of fatal accidents") + 
  theme_few() + 
  geom_smooth(se = FALSE)
```

### Using a loop to create state-specific plots

Next, you will write a loop to write a four-page pdf file with state-specific plots for the states of Colorado, Texas, California, and New York. 

- The data has a column called `STATE`, but it gives state as a one- or two-digit code, rather than by name. These codes are the state Federal Information Processing Standard (FIPS) codes. A dataset with state names and FIPS codes is available at http://www2.census.gov/geo/docs/reference/state.txt. Read that data into an R object called `state_fips` and clean it so the first few lines look like this: 

```{r echo = FALSE, warning = FALSE, message = FALSE}
state_fips <- read_delim("http://www2.census.gov/geo/docs/reference/state.txt",
                         delim = "|") %>%
  rename(state = STATE,
         state_name = STATE_NAME) %>%
  select(state, state_name) %>%
  mutate(state = as.integer(state))
state_fips %>% slice(1:5)
```

- Read the 2015 FARS data into an R object named `accident`. Use all the date and time information to create a column named `date` with the date and time of the accident. Include information on whether the accident was related to drunk driving (FALSE if there were 0 drunk drivers, TRUE if there were one or more), and create columns that gives whether the accident was during the day (7 AM to 7 PM) or not as well as the month of the accident (for this last column, you can either retain it from the original data or recalculate it based on the new `date` variable). Filter out any values where the date-time does not render (i.e., `date` is a missing value). The first few rows of the cleaned dataframe should look like this:

```{r warning = FALSE, message = FALSE, echo = FALSE}
accident <- read_csv("data/accident.csv") %>%
  select(STATE, DAY:MINUTE, DRUNK_DR) %>%
  rename(state = STATE, 
         drunk_dr = DRUNK_DR) %>%
  select(-DAY_WEEK) %>%
  unite(date, DAY:MINUTE, sep = "-") %>%
  mutate(date = dmy_hm(date), 
         drunk_dr = drunk_dr >= 1,
         daytime = hour(date) %in% c(7:19),
         month = month(date)) %>%
  filter(!is.na(date))
accident %>% slice(1:5)
```

- Join the information from `state_fips` into the `accident` dataframe. There may be a few locations in the `state_fips` dataframe that are not included in the `accident` dataframe (e.g., Virgin Islands), so when you join keep all observations in `accident` but only the observations in `state_fips` that match at least one row of `accident`. The first few rows of the joined dataset should look like this: 

```{r echo = FALSE}
accident <- accident %>%
  left_join(state_fips, by = "state")
accident %>% slice(1:5)
```

- Write the code to create boxplots for Colorado of the distribution of total accidents within each month. Create separate boxplots for daytime and nighttime accidents, and facet by whether the accident was related to drunk driving. The plot should look like the plot below.

```{r echo = FALSE, fig.width = 6, fig.height = 3, fig.align = "center"}
which_state <- "Colorado"

accident %>%
  filter(state_name == which_state) %>%
  mutate(drunk_dr = factor(drunk_dr, labels = c("Unrelated to\ndrunk driving",
                                                "Related to\ndrunk driving")),
         daytime = factor(daytime, labels = c("Nighttime", "Daytime"))) %>%
  group_by(daytime, month, drunk_dr) %>%
  summarize(accidents = n()) %>%
  ggplot(aes(x = daytime, y = accidents, group = daytime)) + 
  geom_boxplot() + 
  facet_wrap(~ drunk_dr, ncol = 2) +
  xlab("Time of day") + ylab("# of monthly accidents") + 
  ggtitle(paste("Fatal accidents in", which_state, "in 2015"))
```

- Write a loop to create a plot like the one you just made for Colorado for four different states -- Colorado, Texas, California, and New York. The code should write the plots out to a pdf, with one plot per page of the pdf. (*Hint*: To get a loop to print out a plot created with ggplot, you must explicitly print the plot object. For example, you could assign the plot to `a`, and then you would run `print(a)` within your loop as the last step.) 

#### Example R code

Here is example R code for creating state-specific plots using a loop:

```{r eval = FALSE, message = FALSE, warning = FALSE}
state_fips <- read_delim("http://www2.census.gov/geo/docs/reference/state.txt",
                         delim = "|") %>%
  rename(state = STATE,
         state_name = STATE_NAME) %>%
  select(state, state_name) %>%
  mutate(state = as.integer(state))

accident <- read_csv("data/accident.csv") %>%
  select(STATE, DAY:MINUTE, DRUNK_DR) %>%
  rename(state = STATE, 
         drunk_dr = DRUNK_DR) %>%
  select(-DAY_WEEK) %>%
  unite(date, DAY:MINUTE, sep = "-") %>%
  mutate(date = dmy_hm(date), 
         drunk_dr = drunk_dr >= 1,
         daytime = hour(date) %in% c(7:19),
         month = month(date)) %>%
  filter(!is.na(date)) %>%
  left_join(state_fips, by = "state")

pdf("StateFARSPlots.pdf", height = 3.5, width = 7)
state_list <- c("Colorado", "Texas", "California", "New York")
for(which_state in state_list){
  a <-accident %>%
    filter(state_name == which_state) %>%
    mutate(drunk_dr = factor(drunk_dr, labels = 
                               c("Unrelated to\ndrunk driving",
                                 "Related to\ndrunk driving")),
           daytime = factor(daytime, labels = c("Nighttime", "Daytime"))) %>%
    group_by(daytime, month, drunk_dr) %>%
    summarize(accidents = n()) %>%
    ggplot(aes(x = daytime, y = accidents, group = daytime)) + 
    geom_boxplot() + 
    facet_wrap(~ drunk_dr, ncol = 2) +
    xlab("Time of day") + ylab("# of monthly accidents") + 
    ggtitle(paste("Fatal accidents in", which_state, "in 2015"))
  print(a)
}
dev.off()
```

### Using regression models to explore data

For this exercise, you will need the following packages. If do not have them already, you will need to install them. For the `ggfortify` package, you need to install it from GitHub (uncomment and use the `install_github` code given below):

```{r}
library(ggplot2)
library(broom)

library(devtools)
# install_github('sinhrks/ggfortify')
library(ggfortify)
```


For this part of the exercise, you'll use a dataset on weather, air pollution, and mortality counts in Chicago, IL. This dataset is called `chicagoNMMAPS` and is part of the `dlnm` package. Change the name of the dataframe to something shorter, like `chic`. Check out the data a bit to see what variables you have, and then perform the following tasks:

- Write out (on paper, not in R) the regression equation for regressing dewpoint temperature on temperature. 
- Try fitting a linear regression of dew point temperature (`dptp`) on temperature (`temp`). (Bonus points: Notice anything that seems unusual about these two variables in this dataset? You can find out with `summary`, but it helps if you know a bit about what dewpoint temperature measures.)
Save this model as the object `mod_1`. 
- Based on this regression, does there seem to be a relationship between temperature and dewpoint temperature in Chicago? (Hint: Try using `summary()` on the model object to get more information about the model you fit.) What is the p-value for the coefficient for temperature?
- Plot temperature (x-axis) versus dewpoint temperature (y-axis) for Chicago. Add in the regression line from the model you fit.
- Use `plot()` on the model object to check if some of the assumptions for the regression model seem appropriate.
- Try fitting the regression as a GLM, using `glm()`. Are your coefficients different?
- Does $PM_{10}$ vary by day of the week? (Hint: The `dow` variable is a factor that gives day of the week. You can do an ANOVA analysis by fitting a linear model using this variable as the independent variable, and then run `anova()` on that model, and R will compare it to an intercept-only model.) What day of the week is PM10 generally highest? (Check the model coefficients to figure this out.) Try to write out (on paper) the regression equation for the model you're fitting.
- Try using `glm()` to run a Poisson regression of respiratory deaths (`resp`) on temperature during summer days. Start by creating a subset with just summer days called `summer`. (Hint: Use the `month` variable to do this-- just pull out the subset where the month is 6, 7, or 8, for June, July, and August.) Try to write out the regression equation for the model you're fitting.
- The coefficient for the temperature variable in this model is our best estimate (based on this model) of the **log relative risk** for a one degree Celcius increase in temperature. What is the **relative risk** associated with a one degree Celsius increase?

#### Example R code:

Install and load the `dlnm` package and then load the `chicagoNMMAPS` data. Change the name of the dataframe to `chic`, so it will be shorter to call for the rest of your work. 
```{r, message = FALSE, warning = FALSE}
# install.packages("dlnm")
library(dlnm)
data("chicagoNMMAPS")
chic <- chicagoNMMAPS
```

Fit a linear regression of `dptp` on `temp` and save as the object `mod_1`:

```{r}
mod_1 <- lm(dptp ~ temp, data = chic)
mod_1
```

Use `summary()` to check out a bit more about the model you fit. 

```{r}
summary(mod_1)
```

Now try using functions from the `broom` package to pull the same information about the model, but in a "tidy" format. First, use `glance` to get some summary information about the model:

```{r}
glance(mod_1)
```

Next, use the `tidy` function to get model coefficients in a tidy format:

```{r}
tidy(mod_1)
```

Use the `tidy` function to add model output (e.g., predictions, residuals) to the original dataframe of observed temperatures and dew point temperatures:

```{r warning = FALSE, message = FALSE}
augment(mod_1) %>% 
  slice(1:3)
```

Use the output from `augment` to create a plot of the original data, with the predicted values used to plot a fitted line. 

```{r warning = FALSE, message = FALSE, fig.width = 5, fig.height = 4}
augment(mod_1) %>% 
  ggplot(aes(x = temp, y = dptp)) + 
  geom_point(size = 0.5, alpha = 0.5) + 
  geom_line(aes(x = temp, y = .fitted), color = "red", size = 2)
```


There does seem to be an association between temperature and dewpoint temperature: a unit increase in temperature is associated with a `r round(coef(mod_1)[2], 1)` unit increase in dewpoint temperature. The p-value for the temperature coefficient is <2e-16. This is far below 0.05, which suggests we would be very unlikely to see such a strong association by chance if the null hypothesis, that the two variables are not associated, were true.

Plot these two variables and add in the regression line from the model (note: I've used the `color` option to make the color of the points gray). Use the values from `coef` with a `geom_abline` to add the regression line for the model you fit. 

```{r}
mod_coefs <- coef(mod_1)
ggplot(chic, aes(x = temp, y = dptp)) + 
  geom_point(size = 0.5, col = "gray") + 
  geom_abline(aes(intercept = mod_coefs[1], slope = mod_coefs[2]))
```

Plot some plots to check model assumptions for the model you fit using the `plot()` function on your model object:

```{r, fig.width = 6, fig.height = 6}
par(mfrow = c(2, 2)) # Set to four plots per panel -- 2 rows, 2 columns
plot(mod_1)
par(mfrow = c(1, 1)) # Reset to one plot per panel
```

Try fitting the model using `glm()`. Call it `mod_1a`. Compare the coefficients for the two models. You can use the `coef()` function on an `lm` or `glm` object to pull out just the model coefficients.

```{r}
mod_1a <- glm(dptp ~ temp, data = chic)

coef(mod_1)
coef(mod_1a)
```

The results from the two models are identical.

Fit a model of $PM_{10}$ regressed on day of week, where day of week is a factor. 

```{r}
mod_2 <- lm(pm10 ~ dow, data = chic)
summary(mod_2)
```

Use the `anova()` command to compare this model to a model with only an intercept (i.e., one that only fits a global mean and uses that as the expected value for all of the observations).

```{r}
anova(mod_2)
```

The p-value for an ANOVA of the model with day-of-week coefficients versus the model that just has an intercept is < 2.2e-16. This is well below 0.05, which suggests that day-of-week is associated with PM10 concentration, as a model that includes day-of-week does a much better job of explaining variation in PM10 than a model without it does. (Note, too, that the F value and Pr(>F) for the `anova()` call are identical to the F-statistic information given in the `summary()` of the model object. This will always be true when you're using `anova()` to compare a model to a model with just an intercept.)

Use a boxplot to visually compare PM10 by day of week. 

```{r, fig.height = 3, fig.width = 6, warning = FALSE}
ggplot(chic, aes(x = dow, y = pm10)) + 
  geom_boxplot()
```

Now try the same plot, but try using the `ylim = ` option to change the limits on the y-axis for the graph, so you can get a better idea of the pattern by day of week (some of the extreme values are very high, which makes it hard to compare by eye when the y-axis extends to include them all).

```{r, fig.height = 3, fig.width = 6, message = FALSE}
ggplot(chic, aes(x = dow, y = pm10)) + 
  geom_boxplot() + 
  ylim(c(0, 100))
```

Create a subset called `summer` with just the summer days:

```{r}
summer <- chic %>%
  filter(month %in% 6:8)
```

Use `glm()` to fit a Poisson model of respiratory deaths regressed on temperature. Since you want to fit a Poisson model, use the option `family = poisson(link = "log")`. 

```{r}
mod_3 <- glm(resp ~ temp, data = summer,
             family = poisson(link = "log"))
summary(mod_3)
```

Use the fitted model coefficient to determine the relative risk for a one degree Celcius increase in temperature. First, remember that you can use the `coef()` function to read out the model coefficients. The second of these is the value for the temperature coefficient. That means that you can use indexing (`[2]`) to get just that value. That's the log relative risk; take the exponent to get the relative risk.

```{r}
coef(mod_3)
coef(mod_3)[2]
exp(coef(mod_3)[2])
```

